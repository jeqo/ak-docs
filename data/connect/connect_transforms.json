[{"name":"org.apache.kafka.connect.transforms.InsertField","overview":"Insert field(s) using attributes from the record metadata or a configured static value.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.InsertField$Key</code>) or value (<code>org.apache.kafka.connect.transforms.InsertField$Value</code>).","config":[{"name":"offset.field","documentation":"Field name for Kafka offset - only applicable to sink connectors.<br/>Suffix with <code>!</code> to make this a required field, or <code>?</code> to keep it optional (the default).","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}},{"name":"partition.field","documentation":"Field name for Kafka partition. Suffix with <code>!</code> to make this a required field, or <code>?</code> to keep it optional (the default).","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}},{"name":"static.field","documentation":"Field name for static data field. Suffix with <code>!</code> to make this a required field, or <code>?</code> to keep it optional (the default).","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}},{"name":"static.value","documentation":"Static field value, if field name configured.","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}},{"name":"timestamp.field","documentation":"Field name for record timestamp. Suffix with <code>!</code> to make this a required field, or <code>?</code> to keep it optional (the default).","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}},{"name":"topic.field","documentation":"Field name for Kafka topic. Suffix with <code>!</code> to make this a required field, or <code>?</code> to keep it optional (the default).","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"medium"}}]},{"name":"org.apache.kafka.connect.transforms.ReplaceField","overview":"Filter or rename fields.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.ReplaceField$Key</code>) or value (<code>org.apache.kafka.connect.transforms.ReplaceField$Value</code>).","config":[{"name":"exclude","documentation":"Fields to exclude. This takes precedence over the fields to include.","headers":{"Type":"list","Default":"\"\"","Valid Values":"","Importance":"medium"}},{"name":"include","documentation":"Fields to include. If specified, only these fields will be used.","headers":{"Type":"list","Default":"\"\"","Valid Values":"","Importance":"medium"}},{"name":"renames","documentation":"Field rename mappings.","headers":{"Type":"list","Default":"\"\"","Valid Values":"list of colon-delimited pairs, e.g. <code>foo:bar,abc:xyz</code>","Importance":"medium"}},{"name":"blacklist","documentation":"Deprecated. Use exclude instead.","headers":{"Type":"list","Default":"null","Valid Values":"","Importance":"low"}},{"name":"whitelist","documentation":"Deprecated. Use include instead.","headers":{"Type":"list","Default":"null","Valid Values":"","Importance":"low"}}]},{"name":"org.apache.kafka.connect.transforms.MaskField","overview":"Mask specified fields with a valid null value for the field type (i.e. 0, false, empty string, and so on).<p/>For numeric and string fields, an optional replacement value can be specified that is converted to the correct type.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.MaskField$Key</code>) or value (<code>org.apache.kafka.connect.transforms.MaskField$Value</code>).","config":[{"name":"fields","documentation":"Names of fields to mask.","headers":{"Type":"list","Default":"","Valid Values":"non-empty list","Importance":"high"}},{"name":"replacement","documentation":"Custom value replacement, that will be applied to all 'fields' values (numeric or non-empty string values only).","headers":{"Type":"string","Default":"null","Valid Values":"non-empty string","Importance":"low"}}]},{"name":"org.apache.kafka.connect.transforms.ValueToKey","overview":"Replace the record key with a new key formed from a subset of fields in the record value.","config":[{"name":"fields","documentation":"Field names on the record value to extract as the record key.","headers":{"Type":"list","Default":"","Valid Values":"non-empty list","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.HoistField","overview":"Wrap data using the specified field name in a Struct when schema present, or a Map in the case of schemaless data.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.HoistField$Key</code>) or value (<code>org.apache.kafka.connect.transforms.HoistField$Value</code>).","config":[{"name":"field","documentation":"Field name for the single field that will be created in the resulting Struct or Map.","headers":{"Type":"string","Default":"","Valid Values":"","Importance":"medium"}}]},{"name":"org.apache.kafka.connect.transforms.ExtractField","overview":"Extract the specified field from a Struct when schema present, or a Map in the case of schemaless data. Any null values are passed through unmodified.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.ExtractField$Key</code>) or value (<code>org.apache.kafka.connect.transforms.ExtractField$Value</code>).","config":[{"name":"field","documentation":"Field name to extract.","headers":{"Type":"string","Default":"","Valid Values":"","Importance":"medium"}}]},{"name":"org.apache.kafka.connect.transforms.SetSchemaMetadata","overview":"Set the schema name, version or both on the record's key (<code>org.apache.kafka.connect.transforms.SetSchemaMetadata$Key</code>) or value (<code>org.apache.kafka.connect.transforms.SetSchemaMetadata$Value</code>) schema.","config":[{"name":"schema.name","documentation":"Schema name to set.","headers":{"Type":"string","Default":"null","Valid Values":"","Importance":"high"}},{"name":"schema.version","documentation":"Schema version to set.","headers":{"Type":"int","Default":"null","Valid Values":"","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.TimestampRouter","overview":"Update the record's topic field as a function of the original topic value and the record timestamp.<p/>This is mainly useful for sink connectors, since the topic field is often used to determine the equivalent entity name in the destination system(e.g. database table or search index name).","config":[{"name":"timestamp.format","documentation":"Format string for the timestamp that is compatible with <code>java.text.SimpleDateFormat</code>.","headers":{"Type":"string","Default":"yyyyMMdd","Valid Values":"","Importance":"high"}},{"name":"topic.format","documentation":"Format string which can contain <code>${topic}</code> and <code>${timestamp}</code> as placeholders for the topic and timestamp, respectively.","headers":{"Type":"string","Default":"${topic}-${timestamp}","Valid Values":"","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.RegexRouter","overview":"Update the record topic using the configured regular expression and replacement string.<p/>Under the hood, the regex is compiled to a <code>java.util.regex.Pattern</code>. If the pattern matches the input topic, <code>java.util.regex.Matcher#replaceFirst()</code> is used with the replacement string to obtain the new topic.","config":[{"name":"regex","documentation":"Regular expression to use for matching.","headers":{"Type":"string","Default":"","Valid Values":"valid regex","Importance":"high"}},{"name":"replacement","documentation":"Replacement string.","headers":{"Type":"string","Default":"","Valid Values":"","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.Flatten","overview":"Flatten a nested data structure, generating names for each field by concatenating the field names at each level with a configurable delimiter character. Applies to Struct when schema present, or a Map in the case of schemaless data. Array fields and their contents are not modified. The default delimiter is '.'.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.Flatten$Key</code>) or value (<code>org.apache.kafka.connect.transforms.Flatten$Value</code>).","config":[{"name":"delimiter","documentation":"Delimiter to insert between field names from the input record when generating field names for the output record","headers":{"Type":"string","Default":".","Valid Values":"","Importance":"medium"}}]},{"name":"org.apache.kafka.connect.transforms.Cast","overview":"Cast fields or the entire key or value to a specific type, e.g. to force an integer field to a smaller width. Cast from integers, floats, boolean and string to any other type, and cast binary to string (base64 encoded).<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.Cast$Key</code>) or value (<code>org.apache.kafka.connect.transforms.Cast$Value</code>).","config":[{"name":"spec","documentation":"List of fields and the type to cast them to of the form field1:type,field2:type to cast fields of Maps or Structs. A single type to cast the entire value. Valid types are int8, int16, int32, int64, float32, float64, boolean, and string. Note that binary fields can only be cast to string.","headers":{"Type":"list","Default":"","Valid Values":"list of colon-delimited pairs, e.g. <code>foo:bar,abc:xyz</code>","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.TimestampConverter","overview":"Convert timestamps between different formats such as Unix epoch, strings, and Connect Date/Timestamp types.Applies to individual fields or to the entire value.<p/>Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.TimestampConverter$Key</code>) or value (<code>org.apache.kafka.connect.transforms.TimestampConverter$Value</code>).","config":[{"name":"target.type","documentation":"The desired timestamp representation: string, unix, Date, Time, or Timestamp","headers":{"Type":"string","Default":"","Valid Values":"[string, unix, Date, Time, Timestamp]","Importance":"high"}},{"name":"field","documentation":"The field containing the timestamp, or empty if the entire value is a timestamp","headers":{"Type":"string","Default":"\"\"","Valid Values":"","Importance":"high"}},{"name":"format","documentation":"A SimpleDateFormat-compatible format for the timestamp. Used to generate the output when type=string or used to parse the input if the input is a string.","headers":{"Type":"string","Default":"\"\"","Valid Values":"","Importance":"medium"}},{"name":"unix.precision","documentation":"The desired Unix precision for the timestamp: seconds, milliseconds, microseconds, or nanoseconds. Used to generate the output when type=unix or used to parse the input if the input is a Long.Note: This SMT will cause precision loss during conversions from, and to, values with sub-millisecond components.","headers":{"Type":"string","Default":"milliseconds","Valid Values":"[nanoseconds, microseconds, milliseconds, seconds]","Importance":"low"}}]},{"name":"org.apache.kafka.connect.transforms.Filter","overview":"Drops all records, filtering them from subsequent transformations in the chain. This is intended to be used conditionally to filter out records matching (or not matching) a particular Predicate.","config":[]},{"name":"org.apache.kafka.connect.transforms.InsertHeader","overview":"Add a header to each record.","config":[{"name":"header","documentation":"The name of the header.","headers":{"Type":"string","Default":"","Valid Values":"non-null string","Importance":"high"}},{"name":"value.literal","documentation":"The literal value that is to be set as the header value on all records.","headers":{"Type":"string","Default":"","Valid Values":"non-null string","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.DropHeaders","overview":"Removes one or more headers from each record.","config":[{"name":"headers","documentation":"The name of the headers to be removed.","headers":{"Type":"list","Default":"","Valid Values":"non-empty list","Importance":"high"}}]},{"name":"org.apache.kafka.connect.transforms.HeaderFrom","overview":"Moves or copies fields in the key/value of a record into that record's headers. Corresponding elements of <code>fields</code> and <code>headers</code> together identify a field and the header it should be moved or copied to. Use the concrete transformation type designed for the record key (<code>org.apache.kafka.connect.transforms.HeaderFrom$Key</code>) or value (<code>org.apache.kafka.connect.transforms.HeaderFrom$Value</code>).","config":[{"name":"fields","documentation":"Field names in the record whose values are to be copied or moved to headers.","headers":{"Type":"list","Default":"","Valid Values":"non-empty list","Importance":"high"}},{"name":"headers","documentation":"Header names, in the same order as the field names listed in the fields configuration property.","headers":{"Type":"list","Default":"","Valid Values":"non-empty list","Importance":"high"}},{"name":"operation","documentation":"Either <code>move</code> if the fields are to be moved to the headers (removed from the key/value), or <code>copy</code> if the fields are to be copied to the headers (retained in the key/value).","headers":{"Type":"string","Default":"","Valid Values":"[move, copy]","Importance":"high"}}]}]
